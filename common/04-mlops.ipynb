{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Thinkube AI Lab](../icons/tk_full_logo.svg)\n",
    "\n",
    "# MLOps Introduction ðŸ”¬\n",
    "\n",
    "Learn experiment tracking and LLM observability on Thinkube:\n",
    "- MLflow for ML experiment tracking\n",
    "- Langfuse for LLM tracing and observability\n",
    "- Integration patterns\n",
    "- Best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to MLOps on Thinkube\n",
    "\n",
    "Thinkube provides two complementary tools:\n",
    "\n",
    "### MLflow\n",
    "- Track experiments and hyperparameters\n",
    "- Log metrics over time\n",
    "- Save and version models\n",
    "- Compare runs\n",
    "\n",
    "### Langfuse\n",
    "- Trace LLM calls and chains\n",
    "- Monitor costs and latency\n",
    "- Debug prompts and responses\n",
    "- Analyze LLM performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Basics\n",
    "\n",
    "Connect to MLflow tracking server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MLflow\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# TODO: Set tracking URI from environment\n",
    "# TODO: Set experiment name\n",
    "# TODO: Display MLflow configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log a Simple Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ML experiment\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO: Load iris dataset\n",
    "# TODO: Split into train/test\n",
    "# TODO: Start MLflow run\n",
    "# TODO: Log parameters (n_estimators, max_depth)\n",
    "# TODO: Train model\n",
    "# TODO: Log metrics (accuracy, precision)\n",
    "# TODO: Log model\n",
    "# TODO: End MLflow run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Metrics Over Time\n",
    "\n",
    "Track training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log training metrics over epochs\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Start MLflow run\n",
    "# TODO: Simulate training loop (10 epochs)\n",
    "# TODO: Log loss and accuracy for each epoch\n",
    "# TODO: End MLflow run\n",
    "# TODO: Display run ID and link to UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Multiple Runs\n",
    "\n",
    "Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple experiments with different hyperparameters\n",
    "\n",
    "# TODO: Define hyperparameter grid\n",
    "# TODO: Loop through combinations\n",
    "# TODO: Start MLflow run for each\n",
    "# TODO: Log params and metrics\n",
    "# TODO: Display best run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langfuse Basics\n",
    "\n",
    "Connect to Langfuse for LLM tracing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Langfuse\n",
    "from langfuse import Langfuse\n",
    "import os\n",
    "\n",
    "# TODO: Create Langfuse client with env vars\n",
    "# TODO: Test connection\n",
    "# TODO: Display Langfuse configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace LLM Calls\n",
    "\n",
    "Monitor LLM requests and responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace LLM call with Langfuse\n",
    "from openai import OpenAI\n",
    "\n",
    "# TODO: Create OpenAI client (using LiteLLM gateway)\n",
    "# TODO: Create Langfuse trace\n",
    "# TODO: Call LLM with prompt\n",
    "# TODO: Log generation to Langfuse\n",
    "# TODO: Display trace ID and link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track LLM Chain\n",
    "\n",
    "Trace multi-step LLM workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step LLM chain with tracing\n",
    "\n",
    "# TODO: Create trace for full chain\n",
    "# TODO: Create span for step 1 (summarize)\n",
    "# TODO: Create span for step 2 (translate)\n",
    "# TODO: Log each step with inputs/outputs\n",
    "# TODO: Display trace hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Tracking\n",
    "\n",
    "Monitor LLM usage costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track costs for multiple LLM calls\n",
    "\n",
    "# TODO: Make multiple LLM calls\n",
    "# TODO: Log token usage for each\n",
    "# TODO: Calculate costs\n",
    "# TODO: Display total cost breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Example: ML + LLM\n",
    "\n",
    "Combine MLflow and Langfuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined ML and LLM workflow\n",
    "\n",
    "# TODO: Start MLflow run\n",
    "# TODO: Train ML model, log to MLflow\n",
    "# TODO: Create Langfuse trace\n",
    "# TODO: Use LLM to generate insights about model\n",
    "# TODO: Log LLM call to Langfuse\n",
    "# TODO: Save insights to MLflow run\n",
    "# TODO: Display both run IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### MLflow\n",
    "- âœ… Use descriptive experiment names\n",
    "- âœ… Log all relevant hyperparameters\n",
    "- âœ… Tag runs for easy filtering\n",
    "- âœ… Save models with artifacts\n",
    "- âœ… Add notes and descriptions\n",
    "\n",
    "### Langfuse\n",
    "- âœ… Use traces for complex workflows\n",
    "- âœ… Add metadata for filtering\n",
    "- âœ… Monitor costs regularly\n",
    "- âœ… Track user feedback\n",
    "- âœ… Use sessions for conversations\n",
    "\n",
    "### General\n",
    "- âœ… Clean up old experiments\n",
    "- âœ… Document your workflows\n",
    "- âœ… Review dashboards regularly\n",
    "- âœ… Set up alerts for anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Explore advanced topics:\n",
    "\n",
    "### For Traditional ML:\n",
    "- **ml-gpu/** - GPU-accelerated training\n",
    "- **fine-tuning/** - Fine-tune LLMs with Unsloth\n",
    "\n",
    "### For LLM Applications:\n",
    "- **agent-dev/** - Build multi-agent systems\n",
    "- RAG pipelines with vector search\n",
    "- Production deployment patterns\n",
    "\n",
    "## Resources\n",
    "\n",
    "- MLflow UI: Check your environment variables for URL\n",
    "- Langfuse UI: Check your environment variables for URL\n",
    "- Documentation: https://docs.thinkube.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
